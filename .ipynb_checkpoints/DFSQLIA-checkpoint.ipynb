{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "c3de01e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sys\n",
    "import re\n",
    "import statistics\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from explainerdashboard import ClassifierExplainer, ExplainerDashboard\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "4c31ae26",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SQLIAD:\n",
    "    def carga_Dataset(self, dataframe):\n",
    "        # El dataframe es creado con un dataset\n",
    "        self.df= pd.read_csv(dataframe)\n",
    "        \n",
    "    def carga_Dato(self, dato):\n",
    "        # Crea un dataframe con un dato especifico\n",
    "        # para que el modelo pueda hacer predicciones\n",
    "        # para que el modelo pueda hacer predicciones\n",
    "        self.carga = [dato]\n",
    "        self.df = pd.DataFrame()\n",
    "        self.df['Sentence'] = None\n",
    "        self.df['Sentence'] = self.carga\n",
    "        \n",
    "    def iden_Caract(self):\n",
    "        self.F1 = self.df['Sentence'].str.contains('select ', case=False)\n",
    "        self.F2 = self.df['Sentence'].str.contains('union', case=False)\n",
    "        self.F3 = self.df['Sentence'].str.contains('update', case=False)\n",
    "        self.F4 = self.df['Sentence'].str.contains('set', case=False)\n",
    "        self.F5 = self.df['Sentence'].str.contains('alter', case=False)\n",
    "        self.F6 = self.df['Sentence'].str.contains(' where ', case=False)\n",
    "        self.F7 = self.df['Sentence'].str.contains('like', case=False)\n",
    "        self.F8 = self.df['Sentence'].str.contains(' from ', case=False)\n",
    "        self.F9 = self.df['Sentence'].str.contains(' table ', case=False)\n",
    "        self.F10 = self.df['Sentence'].str.contains('database', case=False)\n",
    "        nuevas_columnas1 = pd.DataFrame({'F1': self.F1, 'F2': self.F2, 'F3': self.F3, 'F4': self.F4, 'F5': self.F5, \n",
    "                                         'F6': self.F6, 'F7': self.F7, 'F8': self.F8, 'F9': self.F9, 'F10': self.F10})\n",
    "        self.df = pd.concat([self.df, nuevas_columnas1], axis=1)\n",
    "        self.F11 = self.df['Sentence'].str.contains('drop ', case=False)\n",
    "        self.F12 = self.df['Sentence'].str.contains('delete ', case=False)\n",
    "        self.F13 = self.df['Sentence'].str.contains('insert ', case=False)\n",
    "        self.F14 = self.df['Sentence'].str.contains('And|Or', case=False, regex=True)\n",
    "        self.F15 = self.df['Sentence'].str.contains('null', case=False)\n",
    "        self.F16 = self.df['Sentence'].str.contains('=', case=False)\n",
    "        self.F17 = self.df['Sentence'].str.contains('information_schema', case=False)\n",
    "        self.F18 = self.df['Sentence'].str.contains('user', case=False)\n",
    "        self.F19 = self.df['Sentence'].str.contains('version', case=False)\n",
    "        self.F20 = self.df['Sentence'].str.contains('load_file', case=False)\n",
    "        nuevas_columnas2 = pd.DataFrame({'F11': self.F11, 'F12': self.F12, 'F13': self.F13, 'F14': self.F14, 'F15': self.F15, \n",
    "                                         'F16': self.F16, 'F17': self.F17, 'F18': self.F18, 'F19': self.F19, 'F20': self.F20})\n",
    "        self.df = pd.concat([self.df, nuevas_columnas2], axis=1)\n",
    "        self.F21 = self.df['Sentence'].str.contains('save', case=False)\n",
    "        self.F22 = self.df['Sentence'].str.contains('!|#|%|$|NUL|SOH|STX|ETX|EOT|@', case=False, regex=True)\n",
    "        self.F23 = self.df['Sentence'].str.contains('&', case=False, regex=False)\n",
    "        self.F24 = self.df['Sentence'].str.contains('|', case=False, regex=False)\n",
    "        self.F25 = self.df['Sentence'].str.contains(',', case=False)\n",
    "        self.F26 = self.df['Sentence'].str.contains(';', case=False)\n",
    "        self.F27 = self.df['Sentence'].str.contains('\\\\', case=False, regex=False)\n",
    "        self.F28 = self.df['Sentence'].str.contains('[-+*/]', case=False, regex=True)\n",
    "        self.F29 = self.df['Sentence'].str.contains('commit|rollback|grant|revoke|declare|remove', case=False, regex=True)\n",
    "        nuevas_columnas3 = pd.DataFrame({'F21': self.F21, 'F22': self.F22, 'F23': self.F23, 'F24': self.F24, 'F25': self.F25, \n",
    "                                         'F26': self.F26, 'F27': self.F27, 'F28': self.F28, 'F29': self.F29})\n",
    "        self.df = pd.concat([self.df, nuevas_columnas3], axis=1)\n",
    "        self.df['F30'] = self.df['Sentence'].str.count(';')\n",
    "        self.grouping_name = 'F30'\n",
    "        self.class_dic = {0: '0' , 1: '0'}\n",
    "        self.df[self.grouping_name] = self.df[self.grouping_name].map(self.class_dic)\n",
    "        self.df['F30'] = self.df['F30'].fillna('1')\n",
    "        self.F31 = self.df['Sentence'].str.contains('/*', case=False, regex=False)\n",
    "        self.F32 = self.df['Sentence'].str.contains('*/', case=False, regex=False)\n",
    "        self.F33 = self.df['Sentence'].str.contains('\\\\x', case=False, regex=False)\n",
    "        self.F34 = self.df['Sentence'].str.contains('\\\\u', case=False, regex=False)\n",
    "        self.F35 = self.df['Sentence'].str.contains('connection', case=False)\n",
    "        self.F36 = self.df['Sentence'].str.contains('xor', case=False)\n",
    "        self.F37 = self.df['Sentence'].str.contains('inner join', case=False)\n",
    "        self.F38 = self.df['Sentence'].str.contains('file|load_file|load_data_infile|into_outfile|into_dumpfile', case=False, regex=True)\n",
    "        self.F39 = self.df['Sentence'].str.contains('OS|Operative System|exec', case=False, regex=True)\n",
    "        self.F40 = self.df['Sentence'].str.count('STRING') + self.df['Sentence'].str.count('string')\n",
    "        nuevas_columnas4 = pd.DataFrame({'F31': self.F31, 'F32': self.F32, 'F33': self.F33, 'F34': self.F34, 'F35': self.F35, \n",
    "                                         'F36': self.F36, 'F37': self.F37, 'F38': self.F38, 'F39': self.F39, 'F40': self.F40})\n",
    "        self.df = pd.concat([self.df, nuevas_columnas4], axis=1)\n",
    "        self.F41 = self.df['Sentence'].str.count('SUBSTR') + self.df['Sentence'].str.count('substr')\n",
    "        self.F42 = self.df['Sentence'].str.count('SUBSTRING') + self.df['Sentence'].str.count('substring')\n",
    "        self.F43 = self.df['Sentence'].str.count('MID') + self.df['Sentence'].str.count('mid')\n",
    "        self.F44 = self.df['Sentence'].str.count('ASC') + self.df['Sentence'].str.count('asc')\n",
    "        self.F45 = self.df['Sentence'].str.count('<')\n",
    "        self.F46 = self.df['Sentence'].str.count('>')\n",
    "        self.F47 = self.df['Sentence'].str.count('\"')\n",
    "        self.F48 = self.df['Sentence'].str.count(\"'\")\n",
    "        self.F49 = self.df['Sentence'].str.contains('exists', case=False)\n",
    "        self.F50 = self.df['Sentence'].str.contains('floor', case=False)\n",
    "        nuevas_columnas5 = pd.DataFrame({'F41': self.F41, 'F42': self.F42, 'F43': self.F43, 'F44': self.F44, 'F45': self.F45, \n",
    "                                         'F46': self.F46, 'F47': self.F47, 'F48': self.F48, 'F49': self.F49, 'F50': self.F50})\n",
    "        self.df = pd.concat([self.df, nuevas_columnas5], axis=1)\n",
    "        self.F51 = self.df['Sentence'].str.contains('rand', case=False)\n",
    "        self.F52 = self.df['Sentence'].str.contains('group', case=False)\n",
    "        self.F53 = self.df['Sentence'].str.contains('order', case=False)\n",
    "        self.F54 = self.df['Sentence'].str.contains('lenght', case=False)\n",
    "        self.F55 = self.df['Sentence'].str.contains('ascii', case=False)\n",
    "        self.F56 = self.df['Sentence'].str.contains('if', case=False)\n",
    "        self.F57 = self.df['Sentence'].str.contains('count', case=False)\n",
    "        self.F58 = self.df['Sentence'].str.contains('sleep', case=False)\n",
    "        self.F59 = self.df['Sentence'].str.contains('between', case=False)\n",
    "        self.F60 = self.df['Sentence'].str.contains('values', case=False)\n",
    "        nuevas_columnas6 = pd.DataFrame({'F51': self.F51, 'F52': self.F52, 'F53': self.F53, 'F54': self.F54, 'F55': self.F55, \n",
    "                                         'F56': self.F56, 'F57': self.F57, 'F58': self.F58, 'F59': self.F59, 'F60': self.F60})\n",
    "        self.df = pd.concat([self.df, nuevas_columnas6], axis=1)\n",
    "        self.F61 = self.df['Sentence'].str.contains('delay', case=False)\n",
    "        self.F62 = self.df['Sentence'].str.contains('wait', case=False)\n",
    "        self.F63 = self.df['Sentence'].str.contains('benchmark', case=False)\n",
    "        self.F64 = self.df['Sentence'].str.contains('indentity_insert', case=False)\n",
    "        self.F65 = self.df['Sentence'].str.contains('truncate table', case=False)\n",
    "        self.F66 = self.df['Sentence'].str.contains('username | password', case=False, regex=True)\n",
    "        self.F67 = self.df['Sentence'].str.contains('user | pass', case=False, regex=True)\n",
    "        self.F68 = self.df['Sentence'].str.contains(\"')\", case=False, regex=False)\n",
    "        self.F69 = self.df['Sentence'].str.contains('limit', case=False)\n",
    "        self.F70 = self.df['Sentence'].str.contains('concat', case=False)\n",
    "        nuevas_columnas7 = pd.DataFrame({'F61': self.F61, 'F62': self.F62, 'F63': self.F63, 'F64': self.F64, 'F65': self.F65, \n",
    "                                         'F66': self.F66, 'F67': self.F67, 'F68': self.F68, 'F69': self.F69, 'F70': self.F70})\n",
    "        self.df = pd.concat([self.df, nuevas_columnas7], axis=1)\n",
    "        self.F71 = self.df['Sentence'].str.contains('ne', case=False)\n",
    "        self.F72 = self.df['Sentence'].str.contains('find', case=False)\n",
    "        self.F73 = self.df['Sentence'].str.contains('eq|gt|gte|lt|it|lte|ite|in|nin', case=False, regex=True)\n",
    "        self.F74 = self.df['Sentence'].str.contains('mod| regex | text', case=False, regex=True)\n",
    "        self.F75 = self.df['Sentence'].str.contains('return', case=False)\n",
    "        self.F76 = self.df['Sentence'].str.contains('return true|return 1', case=False, regex=True)\n",
    "        self.F77 = self.df['Sentence'].str.contains('exists', case=False)\n",
    "        self.F78 = self.df['Sentence'].str.contains('create', case=False, regex=True)\n",
    "        self.F79 = self.df['Sentence'].str.contains('show', case=False, regex=True)\n",
    "        self.F80 = self.df['Sentence'].str.contains('collection', case=False, regex=True)\n",
    "        self.F81 = self.df['Sentence'].str.contains('while(loop)', case=False, regex=False)\n",
    "        nuevas_columnas8 = pd.DataFrame({'F71': self.F71, 'F72': self.F72, 'F73': self.F73, 'F74': self.F74, 'F75': self.F75, \n",
    "                                        'F76': self.F76, 'F77': self.F77, 'F78': self.F78, 'F79': self.F79, 'F80': self.F80,\n",
    "                                        'F81': self.F81})\n",
    "        self.df = pd.concat([self.df, nuevas_columnas8], axis=1)\n",
    "        self.numro = 0\n",
    "        self.Igualdad = []\n",
    "        self.F83 = []\n",
    "        self.Numeros = []\n",
    "        self.Espacios = []\n",
    "        self.Bytes = []\n",
    "        self.Pyc = []\n",
    "        self.Especial = []\n",
    "        self.CantMayus = []\n",
    "        self.LectEscrit = []\n",
    "        self.Palabras_Clave = []\n",
    "        #Patrón de palabras clave sql\n",
    "        self.palabrasclave = [\"select\", \"drop\", \"alter\", \"delete\", \"insert\", \"union\", \"update\", \"set\", \n",
    "                                \"where\", \"like\", \" from\", \"table\", \"between\", \"order\", \"join\", \"create\"]\n",
    "        self.byte_utf8max = []\n",
    "        self.byte_utf8min = []\n",
    "        self.byte_utf8DE = []\n",
    "        for self.vx in self.df['Sentence']:\n",
    "            self.partesPyc = self.df['Sentence'][self.numro].split(';') #Identifica si existe texto despues de un ;\n",
    "            if len(self.partesPyc) > 1:\n",
    "                self.Pyc.append('True')\n",
    "            else:\n",
    "                self.Pyc.append('False')\n",
    "            self.texto =  [str(self.x) for self.x in self.df['Sentence']][self.numro].upper() #Identifica todos los caracteres\n",
    "            self.F83.append(len(self.texto))\n",
    "            self.Numeros.append(len([float(s) for s in re.findall(r'-?\\d+\\.?\\d*', self.df['Sentence'][self.numro])])) #Identifica todos los números\n",
    "            self.espac = 0\n",
    "            for i, char in enumerate(self.df['Sentence'][self.numro]): #Identifica cantidad de espacios\n",
    "                if char == ' ':\n",
    "                    self.espac += 1\n",
    "            self.Espacios.append(self.espac)\n",
    "            self.Especial.append(len([str(s) for s in re.findall(r'[^\\w\\s]', self.df['Sentence'][self.numro])])) #Identifica todos los caracteres especiales\n",
    "            self.baites = sys.getsizeof(self.df['Sentence'][self.numro]) #Identifica el peso en bytes del texto\n",
    "            self.Bytes.append(self.baites)\n",
    "            self.conmay = 0\n",
    "            for char in self.df['Sentence'][self.numro]: #Identifica cuantas mayusculas hay en el texto\n",
    "                if char.isupper():\n",
    "                    self.conmay += 1\n",
    "            self.CantMayus.append(self.conmay)\n",
    "            patron_lectura = r'\\b(?:{})\\b'.format('|'.join(map(re.escape, ['select', ' where', 'order by', 'limit', 'join'])))\n",
    "            patron_escritura = r'\\b(?:{})\\b'.format('|'.join(map(re.escape, ['create table', 'insert into', 'update', 'delete', 'alter table '])))\n",
    "            #Identitica los patrones anteriores y clasifica si el texto contiene \n",
    "            #comandos de escritura en sql, comandos de lectura, ambos o ninguno\n",
    "            if re.search(patron_lectura, self.df['Sentence'][self.numro], re.IGNORECASE) and re.search(patron_escritura, self.df['Sentence'][self.numro], re.IGNORECASE):\n",
    "                self.LectEscrit.append(0)\n",
    "            elif re.search(patron_lectura, self.df['Sentence'][self.numro], re.IGNORECASE) and not re.search(patron_escritura, self.df['Sentence'][self.numro], re.IGNORECASE):\n",
    "                self.LectEscrit.append(1)\n",
    "            elif re.search(patron_escritura, self.df['Sentence'][self.numro], re.IGNORECASE) and not re.search(patron_lectura, self.df['Sentence'][self.numro], re.IGNORECASE):\n",
    "                self.LectEscrit.append(2)\n",
    "            else:\n",
    "                self.LectEscrit.append(3)\n",
    "            #Verifica la cantidad de palabras clave de sql en el texto\n",
    "            self.palcla = 0\n",
    "            for palabra in self.palabrasclave:\n",
    "                self.patronPC = r'\\b' + re.escape(palabra) + r'\\b'\n",
    "                self.coincidencias = re.findall(self.patronPC, self.df['Sentence'][self.numro], re.IGNORECASE)\n",
    "                self.palcla += len(self.coincidencias)\n",
    "            self.Palabras_Clave.append(self.palcla)\n",
    "            bytes_utf8 = []\n",
    "            byte_utf8 = []\n",
    "            for caracter in self.texto:\n",
    "                bytes_utf8 = caracter.encode('utf-8') #Indica el caracter y el numero de byte en protocolo utf-8\n",
    "                byte_utf8.append(len(bytes_utf8)) #Indica solo el número de byte\n",
    "            self.byte_utf8max.append(max(byte_utf8))\n",
    "            self.byte_utf8min.append(min(byte_utf8))\n",
    "            self.lista = self.texto.split(None)\n",
    "            self.numro = self.numro + 1\n",
    "            self.elemento = '='  # elemento a buscar\n",
    "            self.posiciones = []  # nuestra lista para guardar las posiciones\n",
    "            self.posicion = -1  # empezaremos a buscar en posicion + 1 (que es 0 inicialmente)\n",
    "            self.yuyu = 0\n",
    "            try:\n",
    "                while True:\n",
    "                    # buscamos empezando a buscar desde la última posición encontrada\n",
    "                    self.posicion = self.lista.index(self.elemento, self.posicion+1)\n",
    "                    self.posiciones.append(self.posicion)\n",
    "                    self.un = self.lista[self.posicion-1]\n",
    "                    self.en = self.lista[self.posicion+1]\n",
    "                    if self.en == self.un:\n",
    "                        self.yuyu = 1\n",
    "            except:\n",
    "                pass  # no hacemos nada si index lanza ValueError\n",
    "            if self.yuyu == 1:\n",
    "                self.Igualdad.append('1')\n",
    "            else:\n",
    "                self.Igualdad.append('0')\n",
    "        self.df['F82'] = self.Igualdad\n",
    "        self.df['F82'] = self.df['F82'].astype(int)\n",
    "        self.df['F83'] = self.F83 #Cantidad de caracteres en el texto\n",
    "        self.df['F84'] = self.Numeros\n",
    "        self.df['F85'] = self.df['F84']/self.df['F83'] #Relacion espacios y texto completo\n",
    "        self.df['F86'] = self.Espacios\n",
    "        self.df['F87'] = self.df['F86']/self.df['F83'] #Relacion espacios y texto completo\n",
    "        self.df['F88'] = self.Especial\n",
    "        self.df['F89'] = self.df['F88']/self.df['F83'] #Relacion caracteres especiales y texto completo\n",
    "        #Cantidad de \"texto normal\" (no numeros, no caracteres especiales, no espacios)\n",
    "        self.df['F90'] = self.df['F83']-(self.df['F84']+self.df['F86']+self.df['F88'])\n",
    "        self.df['F91'] = self.Bytes\n",
    "        self.df['F92'] = self.Pyc\n",
    "        self.df['F92'] = self.df['F92'].astype(bool)\n",
    "        self.df['F93'] = self.CantMayus\n",
    "        self.df['F94'] = self.LectEscrit\n",
    "        self.df['F95'] = self.Palabras_Clave\n",
    "        self.df['F96'] = self.byte_utf8max\n",
    "        self.df['F97'] = self.byte_utf8min\n",
    "        self.F98 = self.df['Sentence'].str.contains('\\s{2,}', case=False, regex=True)\n",
    "        self.F99 = self.df['Sentence'].str.contains('\\dX', case=False, regex=True)\n",
    "        self.F100 = self.df['Sentence'].str.contains('Select\\s\\d', case=False, regex=True)\n",
    "        self.F101 = self.df['Sentence'].str.contains('version()', case=False, regex=False)\n",
    "        self.F102 = self.df['Sentence'].str.contains('server_version|--version|-v|locate bin', case=False, regex=True)\n",
    "        self.F103 = self.df['Sentence'].str.count('null')\n",
    "        self.F104 = self.df['Sentence'].str.count('=')\n",
    "        self.F105 = self.df['Sentence'].str.contains('query', case=False)\n",
    "        self.F106 = self.df['Sentence'].str.contains('union all', case=False)\n",
    "        self.F107 = self.df['Sentence'].str.contains('mysobjects|sysobjects', case=False, regex=True)\n",
    "        self.F108 = self.df['Sentence'].str.contains('if', case=False)\n",
    "        self.F109 = self.df['Sentence'].str.contains(\"'''\", case=False)\n",
    "        self.F110 = self.df['Sentence'].str.contains('Cast|Convert|Collate', case=False, regex=True)\n",
    "        nuevas_columnas9 = pd.DataFrame({'F98': self.F98, 'F99': self.F99, 'F100': self.F100, 'F101': self.F101, 'F102': \n",
    "                                          self.F102, 'F103': self.F103, 'F104': self.F104, 'F105': self.F105, 'F106': self.F106, \n",
    "                                          'F107': self.F107, 'F108': self.F108, 'F109': self.F109, 'F110': self.F110})\n",
    "        self.df = pd.concat([self.df, nuevas_columnas9], axis=1)\n",
    "        self.F111 = self.df['Sentence'].str.contains('; set identity_insert', case=False, regex=False)\n",
    "        self.F112 = self.df['Sentence'].str.contains('; truncate table', case=False, regex=False)\n",
    "        self.F113 = self.df['Sentence'].str.contains('; drop table', case=False, regex=False)\n",
    "        self.F114 = self.df['Sentence'].str.contains('; update', case=False, regex=False)\n",
    "        self.F115 = self.df['Sentence'].str.contains('; insert into', case=False, regex=False)\n",
    "        self.F116 = self.df['Sentence'].str.contains('; delete', case=False, regex=False)\n",
    "        self.F117 = self.df['Sentence'].str.contains('; insert', case=False, regex=False)\n",
    "        self.F118 = self.df['Sentence'].str.contains(\"''))/*&\", case=False, regex=False)\n",
    "        self.F119 = self.df['Sentence'].str.contains('/*&', case=False, regex=False)\n",
    "        self.F120 = self.df['Sentence'].str.contains('And\\s\\d', case=False, regex=True)\n",
    "        nuevas_columnas10 = pd.DataFrame({'F111': self.F111, 'F112': self.F112, 'F113': self.F113, 'F114': self.F114, \n",
    "                                          'F115': self.F115, 'F116': self.F116, 'F117': self.F117, 'F118': self.F118, \n",
    "                                          'F119': self.F119, 'F120': self.F120})\n",
    "        self.df = pd.concat([self.df, nuevas_columnas10], axis=1)\n",
    "        self.F121 = self.df['Sentence'].str.contains(';]/', case=False, regex=False)\n",
    "        self.F122 = self.df['Sentence'].str.contains('createtable()', case=False, regex=False)\n",
    "        self.F123 = self.df['Sentence'].str.contains('showtable()', case=False, regex=False)\n",
    "        self.F124 = self.df['Sentence'].str.contains('createcollection()', case=False, regex=False)\n",
    "        self.F125 = self.df['Sentence'].str.contains('drop()', case=False, regex=False)\n",
    "        self.F126 = self.df['Sentence'].str.contains('dropdatabase()', case=False, regex=False)\n",
    "        #Detecta si existe Or seguido de otra palabra\n",
    "        self.F127 = self.df['Sentence'].str.contains(r'or\\s+\\S+', case=False, regex=True)\n",
    "        self.F128 = self.df['Sentence'].str.contains(r'%\\s+\\S+', case=False, regex=True)\n",
    "        #Detecta si existen Prepocisiones\n",
    "        self.F129 = self.df['Sentence'].str.contains(' a | ante | bajo | cabe | con | contra | de | desde | durante | en | entre | hacia | hasta | mediante | para | por | según | sin | so | sobre | tras | versus | vía | aboard | about | above | across | after | against | along  | amid | among | anti | around | as | at | before | behindbelow | beneath | beside | besides | between | beyond | but | by | concerning | considering | despite | down | during | except | excepting | excluding | following | for | from | in | inside | into | like | minus | near | of | off | on | onto | opposite | outside | over | past | upon | versus | via | with | within | without ', case=False, regex=True)\n",
    "        #Detecta si existen Articulos\n",
    "        self.F130 = self.df['Sentence'].str.contains(' el | la | lo | los | las | un | una | unos | unas | a | an | the ', case=False, regex=True)\n",
    "        nuevas_columnas11 = pd.DataFrame({'F121': self.F121, 'F122': self.F122, 'F123': self.F123, 'F124': self.F124, \n",
    "                                          'F125': self.F125, 'F126': self.F126, 'F127': self.F127, 'F128': self.F128, \n",
    "                                          'F129': self.F129, 'F130': self.F130})\n",
    "        self.df = pd.concat([self.df, nuevas_columnas11], axis=1)\n",
    "        \n",
    "    def lvl1_Cargar_Caract(self):\n",
    "        # Se seleccionan las caracterisitcas de los modelos para el nivel 1\n",
    "        self.data1 = self.df[['Label', 'F1', 'F2', 'F4', 'F6', 'F7', 'F8', 'F14', \n",
    "                              'F16', 'F43', 'F51', 'F52', 'F53', 'F54', 'F56', \n",
    "                              'F58', 'F59', 'F65', 'F66', 'F77', 'F78', 'F83', 'F85', \n",
    "                              'F88', 'F93', 'F97', 'F99', 'F100', 'F101', 'F108', \n",
    "                              'F110', 'F113', 'F117', 'F119', 'F121']]\n",
    "        \n",
    "    def carga_Features1(self):\n",
    "        # Guardamos solo las caracteristicas para que los modelos del nivel 1 \n",
    "        # puedan hacer la prediccion\n",
    "        self.Xy1 = self.df[['F1', 'F2', 'F4', 'F6', 'F7', 'F8', 'F14', \n",
    "                            'F16', 'F43', 'F51', 'F52', 'F53', 'F54', 'F56', \n",
    "                            'F58', 'F59', 'F65', 'F66', 'F77', 'F78', 'F83', 'F85', \n",
    "                            'F88', 'F93', 'F97', 'F99', 'F100', 'F101', 'F108', \n",
    "                            'F110', 'F113', 'F117', 'F119', 'F121']]\n",
    "        \n",
    "    def lvl1_div_Datos(self):\n",
    "        # Dividimos los datos en entrenamiento y prueba\n",
    "        # X son nuestras variables independientes\n",
    "        self.X1 = self.data1.drop([\"Label\"],axis = 1)\n",
    "        \n",
    "        # y es nuestra variable dependiente\n",
    "        self.y1 = self.data1.Label\n",
    "        \n",
    "        # División 75% de datos para entrenamiento, 25% de datos para test\n",
    "        self.X_train1, self.X_test1, self.y_train1, self.y_test1 = train_test_split(self.X1, self.y1, random_state=0)\n",
    "        \n",
    "    def lvl1_creacion_DT(self):\n",
    "        # Creamos el modelo de Arbol de Decisión (y configuramos el número máximo de nodos-hoja)\n",
    "        self.Dt_model1 = tree.DecisionTreeClassifier(random_state = 0)\n",
    "    \n",
    "    def lvl1_entren_DT(self):\n",
    "        # Se entrena el arbol de decision del nivel 1\n",
    "        self.Dt_model1.fit(self.X_train1, self.y_train1)\n",
    "        \n",
    "    def lvl1_creacion_RF(self):\n",
    "        # Creamos el modelo Random Forest (se configura el numero de aboles, \n",
    "        # numero minimo de hojas y profundidad maxima)\n",
    "        self.BA_model1 = RandomForestClassifier(n_estimators = 20, random_state = 2016,)\n",
    "    \n",
    "    def lvl1_entren_RF(self):\n",
    "        # Se entrena el random forest del nivel 1\n",
    "        self.BA_model1.fit(self.X_train1, self.y_train1)\n",
    "        \n",
    "    def lvl1_datos_Entren_DT(self):\n",
    "        # Muestra el accuracy de los datos de entrenamiento del DT1\n",
    "        print(\"Accuracy de entrenamiento Decision: \", self.Dt_model1.score(self.X_train1, self.y_train1))\n",
    "        self.dt_pred1 = self.Dt_model1.predict(self.X_train1)\n",
    "        # Muestra el F1 score de los datos de entrenamiento del DT1\n",
    "        print('F1 score:', f1_score(self.y_train1, self.dt_pred1))\n",
    "        # Muestra la matriz de confusion de los datos de entrenamiento del DT1\n",
    "        self.matriz = confusion_matrix(self.y_train1, self.dt_pred1)\n",
    "        plot_confusion_matrix(conf_mat=self.matriz, figsize=(4,4), show_normed=False)\n",
    "        plt.tight_layout()\n",
    "        plt.title('Matriz de Entrenamiento DT')\n",
    "        \n",
    "    def lvl1_datos_Entren_RF(self):\n",
    "        # Muestra el accuracy de los datos de entrenamiento del RF1\n",
    "        print(\"Accuracy de entrenamiento Random Forest: \", self.BA_model1.score(self.X_train1, self.y_train1))\n",
    "        self.rf_pred1 = self.BA_model1.predict(self.X_train1)\n",
    "        # Muestra el F1 score de los datos de entrenamiento del RF1\n",
    "        print('F1 score:', f1_score(self.y_train1, self.rf_pred1))\n",
    "        # Muestra la matriz de confusion de los datos de entrenamiento del RF1\n",
    "        self.matriz = confusion_matrix(self.y_train1, self.rf_pred1)\n",
    "        plot_confusion_matrix(conf_mat=self.matriz, figsize=(4,4), show_normed=False)\n",
    "        plt.tight_layout()\n",
    "        plt.title('Matriz de Entrenamiento RF')\n",
    "        \n",
    "    def lvl1_datos_Prueba_DT(self):\n",
    "        # Muestra el accuracy de los datos de prueba del DT1\n",
    "        print(\"Accuracy de prueba Decision Tree: \", self.Dt_model1.score(self.X_test1, self.y_test1))\n",
    "        self.dt_pred1 = self.Dt_model1.predict(self.X_test1)\n",
    "        # Muestra el F1 score de los datos de prueba del DT1\n",
    "        print('F1 score:', f1_score(self.y_test1, self.dt_pred1))\n",
    "        # Muestra la matriz de confusion de los datos de prueba del DT1\n",
    "        self.matriz = confusion_matrix(self.y_test1, self.dt_pred1)\n",
    "        plot_confusion_matrix(conf_mat=self.matriz, figsize=(4,4), show_normed=False)\n",
    "        plt.tight_layout()\n",
    "        plt.title('Matriz de Prueba DT')\n",
    "        \n",
    "    def lvl1_datos_Prueba_RF(self):\n",
    "        # Muestra el accuracy de los datos de prueba del RF1\n",
    "        print(\"Accuracy de prueba Random Forest: \", self.BA_model1.score(self.X_test1, self.y_test1))\n",
    "        self.rf_pred1 = self.BA_model1.predict(self.X_test1)\n",
    "        # Muestra el F1 score de los datos de prueba del RF1\n",
    "        print('F1 score:', f1_score(self.y_test1, self.rf_pred1))\n",
    "        # Muestra la matriz de confusion de los datos de prueba del RF1\n",
    "        self.matriz = confusion_matrix(self.y_test1, self.rf_pred1)\n",
    "        plot_confusion_matrix(conf_mat=self.matriz, figsize=(4,4), show_normed=False)\n",
    "        plt.tight_layout()\n",
    "        plt.title('Matriz de Prueba RF')\n",
    "            \n",
    "    def generacion_NC1(self):\n",
    "        #Cargara todo el dataset nuevamente para \"def generacion_NC1\"\n",
    "        self.xxx1 = self.data1.drop([\"Label\"],axis = 1)\n",
    "        #self.yyy1 = self.data1.Label\n",
    "        #Generara la nueva caracteristica para todo el dataset\n",
    "        #Solo usar para entrenamiento\n",
    "        numm1 = 0\n",
    "        self.F131 = []\n",
    "        self.F132 = []\n",
    "        self.dt_pred1 = self.Dt_model1.predict(self.xxx1)\n",
    "        self.rf_pred1 = self.BA_model1.predict(self.xxx1)\n",
    "        for vc in self.xxx1.iterrows():\n",
    "            self.F131.append(self.dt_pred1[numm1])\n",
    "            self.F132.append(self.rf_pred1[numm1])\n",
    "            numm1 = numm1 + 1\n",
    "        self.df['F131'] = self.F131\n",
    "        self.df['F132'] = self.F132\n",
    "        \n",
    "    def gNC1(self):\n",
    "        #Generara la nueva caracteristica para todo el dataset\n",
    "        self.F131 = []\n",
    "        self.F132 = []\n",
    "        self.dt_pred1 = self.Dt_model1.predict(self.Xy1)\n",
    "        self.rf_pred1 = self.BA_model1.predict(self.Xy1)\n",
    "        self.df['F131'] = self.dt_pred1\n",
    "        self.df['F132'] = self.rf_pred1\n",
    "        \n",
    "    def lvl2_Cargar_Caract(self):\n",
    "        #Se seleccionan las caracterisitcas del modelo\n",
    "        self.data2 = self.df[['Label', 'F22', 'F23', 'F24', 'F25', 'F26', 'F27', \n",
    "                              'F32', 'F33', 'F35', 'F39', 'F40', 'F41', 'F44', \n",
    "                              'F45', 'F46', 'F47', 'F50', 'F70', 'F71', 'F79', \n",
    "                              'F84', 'F86', 'F92', 'F96', 'F98', 'F102', 'F106', \n",
    "                              'F109', 'F120', 'F123', 'F126', 'F128', 'F131', 'F132']]\n",
    "        \n",
    "    def carga_Features2(self):\n",
    "        # Guardamos solo las caracteristicas para que los modelos del nivel 2 \n",
    "        # puedan hacer la prediccion\n",
    "        self.Xy2 = self.df[['F22', 'F23', 'F24', 'F25', 'F26', 'F27', \n",
    "                            'F32', 'F33', 'F35', 'F39', 'F40', 'F41', 'F44', \n",
    "                            'F45', 'F46', 'F47', 'F50', 'F70', 'F71', 'F79', \n",
    "                            'F84', 'F86', 'F92', 'F96', 'F98', 'F102', 'F106', \n",
    "                            'F109', 'F120', 'F123', 'F126', 'F128', 'F131', 'F132']]\n",
    "    \n",
    "    def lvl2_div_Datos(self):\n",
    "        # Dividimos los datos en entrenamiento y prueba\n",
    "        # X son nuestras variables independientes\n",
    "        self.X2 = self.data2.drop([\"Label\"],axis = 1)\n",
    "\n",
    "        # y es nuestra variable dependiente\n",
    "        self.y2 = self.data2.Label\n",
    "        \n",
    "        # División 75% de datos para entrenamiento, 25% de datos para test\n",
    "        self.X_train2, self.X_test2, self.y_train2, self.y_test2 = train_test_split(self.X2, self.y2,random_state=0)\n",
    "        \n",
    "    def lvl2_creacion_DT(self):\n",
    "        # Creamos el modelo de Arbol de Decisión (y configuramos el número máximo de nodos-hoja)\n",
    "        self.Dt_model2 = tree.DecisionTreeClassifier(random_state = 0)\n",
    "    \n",
    "    def lvl2_entren_DT(self):\n",
    "        # Se entrena el arbol de decision del nivel 2\n",
    "        self.Dt_model2.fit(self.X_train2, self.y_train2)\n",
    "        \n",
    "    def lvl2_creacion_RF(self):\n",
    "        # Creamos el modelo Random Forest (se configura el numero de aboles, \n",
    "        # numero minimo de hojas y profundidad maxima)\n",
    "        self.BA_model2 = RandomForestClassifier(n_estimators = 20, random_state = 2016,)\n",
    "    \n",
    "    def lvl2_entren_RF(self):\n",
    "        # Se entrena el random forest del nivel 2\n",
    "        self.BA_model2.fit(self.X_train2, self.y_train2)\n",
    "        \n",
    "    def lvl2_datos_Entren_DT(self):\n",
    "        # Muestra el accuracy de los datos de entrenamiento del DT2\n",
    "        print(\"Accuracy de entrenamiento Decision: \", self.Dt_model2.score(self.X_train2, self.y_train2))\n",
    "        self.dt_pred2 = self.Dt_model2.predict(self.X_train2)\n",
    "        # Muestra el F1 score de los datos de entrenamiento del DT2\n",
    "        print('F1 score:', f1_score(self.y_train2, self.dt_pred2))\n",
    "        # Muestra la matriz de confusion de los datos de entrenamiento del DT2\n",
    "        self.matriz = confusion_matrix(self.y_train2, self.dt_pred2)\n",
    "        plot_confusion_matrix(conf_mat=self.matriz, figsize=(4,4), show_normed=False)\n",
    "        plt.tight_layout()\n",
    "        plt.title('Matriz de Entrenamiento DT')\n",
    "        \n",
    "    def lvl2_datos_Entren_RF(self):\n",
    "        # Muestra el accuracy de los datos de entrenamiento del RF2\n",
    "        print(\"Accuracy de entrenamiento Random Forest: \", self.BA_model2.score(self.X_train2, self.y_train2))\n",
    "        self.rf_pred2 = self.BA_model2.predict(self.X_train2)\n",
    "        # Muestra el F1 score de los datos de entrenamiento del RF2\n",
    "        print('F1 score:', f1_score(self.y_train2, self.rf_pred2))\n",
    "        # Muestra la matriz de confusion de los datos de entrenamiento del RF2\n",
    "        self.matriz = confusion_matrix(self.y_train2, self.rf_pred2)\n",
    "        plot_confusion_matrix(conf_mat=self.matriz, figsize=(4,4), show_normed=False)\n",
    "        plt.tight_layout()\n",
    "        plt.title('Matriz de Entrenamiento RF')\n",
    "        \n",
    "    def lvl2_datos_Prueba_DT(self):\n",
    "        # Muestra el accuracy de los datos de prueba del DT2\n",
    "        print(\"Accuracy de prueba Decision Tree: \", self.Dt_model2.score(self.X_test2, self.y_test2))\n",
    "        self.dt_pred2 = self.Dt_model2.predict(self.X_test2)\n",
    "        # Muestra el F1 score de los datos de prueba del DT2\n",
    "        print('F1 score:', f1_score(self.y_test2, self.dt_pred2))\n",
    "        # Muestra la matriz de confusion de los datos de prueba del DT2\n",
    "        self.matriz = confusion_matrix(self.y_test2, self.dt_pred2)\n",
    "        plot_confusion_matrix(conf_mat=self.matriz, figsize=(4,4), show_normed=False)\n",
    "        plt.tight_layout()\n",
    "        plt.title('Matriz de Prueba DT')\n",
    "        \n",
    "    def lvl2_datos_Prueba_RF(self):\n",
    "        # Muestra el accuracy de los datos de prueba del RF2\n",
    "        print(\"Accuracy de prueba Random Forest: \", self.BA_model2.score(self.X_test2, self.y_test2))\n",
    "        self.rf_pred2 = self.BA_model2.predict(self.X_test2)\n",
    "        # Muestra el F1 score de los datos de prueba del RF2\n",
    "        print('F1 score:', f1_score(self.y_test2, self.rf_pred2))\n",
    "        # Muestra la matriz de confusion de los datos de prueba del RF2\n",
    "        self.matriz = confusion_matrix(self.y_test2, self.rf_pred2)\n",
    "        plot_confusion_matrix(conf_mat=self.matriz, figsize=(4,4), show_normed=False)\n",
    "        plt.tight_layout()\n",
    "        plt.title('Matriz de Prueba RF')\n",
    "        \n",
    "    def generacion_NC2(self):\n",
    "        #Cargara todo el dataset nuevamente para \"def generacion_NC1\"\n",
    "        self.xxx2 = self.data2.drop([\"Label\"],axis = 1)\n",
    "        #self.yyy1 = self.data1.Label\n",
    "        #Generara la nueva caracteristica para todo el dataset\n",
    "        #Solo usar para entrenamiento\n",
    "        numm2 = 0\n",
    "        self.F133 = []\n",
    "        self.F134 = []\n",
    "        self.dt_pred2 = self.Dt_model2.predict(self.xxx2)\n",
    "        self.rf_pred2 = self.BA_model2.predict(self.xxx2)\n",
    "        for vc in self.xxx2.iterrows():\n",
    "            self.F133.append(self.dt_pred2[numm2])\n",
    "            self.F134.append(self.rf_pred2[numm2])\n",
    "            numm2 = numm2 + 1\n",
    "        self.df['F133'] = self.F133\n",
    "        self.df['F134'] = self.F134\n",
    "        \n",
    "    def gNC2(self):\n",
    "        #Generara la nueva caracteristica para todo el dataset\n",
    "        self.F133 = []\n",
    "        self.F134 = []\n",
    "        self.dt_pred2 = self.Dt_model2.predict(self.Xy2)\n",
    "        self.rf_pred2 = self.BA_model2.predict(self.Xy2)\n",
    "        self.df['F133'] = self.dt_pred2\n",
    "        self.df['F134'] = self.rf_pred2\n",
    "    \n",
    "    def lvl3_Cargar_Caract(self):\n",
    "        #Se seleccionan las caracterisitcas del modelo\n",
    "        self.data3 = self.df[['Label', 'F17', 'F18', 'F19', 'F20', 'F21', 'F34', \n",
    "                              'F36', 'F38', 'F48', 'F49', 'F55', 'F57', 'F61', \n",
    "                              'F62', 'F63', 'F67', 'F68', 'F72', 'F73', 'F74', \n",
    "                              'F75', 'F76', 'F87', 'F95', 'F103', 'F111', 'F115', \n",
    "                              'F116', 'F118', 'F122', 'F124', 'F125', 'F127', \n",
    "                              'F128', 'F133', 'F134']]\n",
    "        \n",
    "    def carga_Features3(self):\n",
    "        # Guardamos solo las caracteristicas para que los modelos del nivel 3 \n",
    "        # puedan hacer la prediccion\n",
    "        self.Xy3 = self.df[['F17', 'F18', 'F19', 'F20', 'F21', 'F34', \n",
    "                            'F36', 'F38', 'F48', 'F49', 'F55', 'F57', 'F61', \n",
    "                            'F62', 'F63', 'F67', 'F68', 'F72', 'F73', 'F74', \n",
    "                            'F75', 'F76', 'F87', 'F95', 'F103', 'F111', 'F115', \n",
    "                            'F116', 'F118', 'F122', 'F124', 'F125', 'F127', \n",
    "                            'F128', 'F133', 'F134']]\n",
    "        \n",
    "    def lvl3_div_Datos(self):\n",
    "        # Dividimos los datos en entrenamiento y prueba\n",
    "        # X son nuestras variables independientes\n",
    "        self.X3 = self.data3.drop([\"Label\"],axis = 1)\n",
    "        \n",
    "        # y es nuestra variable dependiente\n",
    "        self.y3 = self.data3.Label\n",
    "        \n",
    "        # División 75% de datos para entrenamiento, 25% de datos para test\n",
    "        self.X_train3, self.X_test3, self.y_train3, self.y_test3 = train_test_split(self.X3, self.y3,random_state=0)\n",
    "        \n",
    "    def lvl3_creacion_DT(self):\n",
    "        # Creamos el modelo de Arbol de Decisión (y configuramos el número máximo de nodos-hoja)\n",
    "        self.Dt_model3 = tree.DecisionTreeClassifier(random_state = 0)\n",
    "    \n",
    "    def lvl3_entren_DT(self):\n",
    "        # Se entrena el arbol de decision del nivel 3\n",
    "        self.Dt_model3.fit(self.X_train3, self.y_train3)\n",
    "        \n",
    "    def lvl3_creacion_RF(self):\n",
    "        # Creamos el modelo Random Forest (se configura el numero de aboles, \n",
    "        # numero minimo de hojas y profundidad maxima)\n",
    "        self.BA_model3 = RandomForestClassifier(n_estimators = 20, random_state = 2016,)\n",
    "    \n",
    "    def lvl3_entren_RF(self):\n",
    "        # Se entrena el random forest del nivel 3\n",
    "        self.BA_model3.fit(self.X_train3, self.y_train3)\n",
    "        \n",
    "    def lvl3_datos_Entren_DT(self):\n",
    "        # Muestra el accuracy de los datos de entrenamiento del DT3\n",
    "        print(\"Accuracy de entrenamiento Decision: \", self.Dt_model3.score(self.X_train3, self.y_train3))\n",
    "        self.dt_pred3 = self.Dt_model3.predict(self.X_train3)\n",
    "        # Muestra el F1 score de los datos de entrenamiento del DT3\n",
    "        print('F1 score:', f1_score(self.y_train3, self.dt_pred3))\n",
    "        # Muestra la matriz de confusion de los datos de entrenamiento del DT3\n",
    "        self.matriz = confusion_matrix(self.y_train3, self.dt_pred3)\n",
    "        plot_confusion_matrix(conf_mat=self.matriz, figsize=(4,4), show_normed=False)\n",
    "        plt.tight_layout()\n",
    "        plt.title('Matriz de Entrenamiento DT')\n",
    "        \n",
    "    def lvl3_datos_Entren_RF(self):\n",
    "        # Muestra el accuracy de los datos de entrenamiento del RF3\n",
    "        print(\"Accuracy de entrenamiento Random Forest: \", self.BA_model3.score(self.X_train3, self.y_train3))\n",
    "        self.rf_pred3 = self.BA_model3.predict(self.X_train3)\n",
    "        # Muestra el F1 score de los datos de entrenamiento del RF3\n",
    "        print('F1 score:', f1_score(self.y_train3, self.rf_pred3))\n",
    "        # Muestra la matriz de confusion de los datos de entrenamiento del RF3\n",
    "        self.matriz = confusion_matrix(self.y_train3, self.rf_pred3)\n",
    "        plot_confusion_matrix(conf_mat=self.matriz, figsize=(4,4), show_normed=False)\n",
    "        plt.tight_layout()\n",
    "        plt.title('Matriz de Entrenamiento RF')\n",
    "        \n",
    "    def lvl3_datos_Prueba_DT(self):\n",
    "        # Muestra el accuracy de los datos de prueba del DT3\n",
    "        print(\"Accuracy de prueba Decision Tree: \", self.Dt_model3.score(self.X_test3, self.y_test3))\n",
    "        self.dt_pred3 = self.Dt_model3.predict(self.X_test3)\n",
    "        # Muestra el F1 score de los datos de prueba del DT3\n",
    "        print('F1 score:', f1_score(self.y_test3, self.dt_pred3))\n",
    "        # Muestra la matriz de confusion de los datos de prueba del DT3\n",
    "        self.matriz = confusion_matrix(self.y_test3, self.dt_pred3)\n",
    "        plot_confusion_matrix(conf_mat=self.matriz, figsize=(4,4), show_normed=False)\n",
    "        plt.tight_layout()\n",
    "        plt.title('Matriz de Prueba DT')\n",
    "        \n",
    "    def lvl3_datos_Prueba_RF(self):\n",
    "        # Muestra el accuracy de los datos de prueba del RF3\n",
    "        print(\"Accuracy de prueba Random Forest: \", self.BA_model3.score(self.X_test3, self.y_test3))\n",
    "        self.rf_pred3 = self.BA_model3.predict(self.X_test3)\n",
    "        # Muestra el F1 score de los datos de prueba del RF3\n",
    "        print('F1 score:', f1_score(self.y_test3, self.rf_pred3))\n",
    "        # Muestra la matriz de confusion de los datos de prueba del RF3\n",
    "        self.matriz = confusion_matrix(self.y_test3, self.rf_pred3)\n",
    "        plot_confusion_matrix(conf_mat=self.matriz, figsize=(4,4), show_normed=False)\n",
    "        plt.tight_layout()\n",
    "        plt.title('Matriz de Prueba RF')\n",
    "        \n",
    "    def generacion_NC3(self):\n",
    "        #Cargara todo el dataset nuevamente para \"def generacion_NC1\"\n",
    "        self.xxx3 = self.data3.drop([\"Label\"],axis = 1)\n",
    "        #self.yyy1 = self.data1.Label\n",
    "        #Generara la nueva caracteristica para todo el dataset\n",
    "        #Solo usar para entrenamiento\n",
    "        numm3 = 0\n",
    "        self.F135 = []\n",
    "        self.F136 = []\n",
    "        self.dt_pred3 = self.Dt_model3.predict(self.xxx3)\n",
    "        self.rf_pred3 = self.BA_model3.predict(self.xxx3)\n",
    "        for vc in self.xxx3.iterrows():\n",
    "            self.F135.append(self.dt_pred3[numm3])\n",
    "            self.F136.append(self.rf_pred3[numm3])\n",
    "            numm3 = numm3 + 1\n",
    "        self.df['F135'] = self.F135\n",
    "        self.df['F136'] = self.F136\n",
    "        \n",
    "    def gNC3(self):\n",
    "        #Generara la nueva caracteristica para todo el dataset\n",
    "        self.F135 = []\n",
    "        self.F136 = []\n",
    "        self.dt_pred3 = self.Dt_model3.predict(self.Xy3)\n",
    "        self.rf_pred3 = self.BA_model3.predict(self.Xy3)\n",
    "        self.df['F135'] = self.dt_pred3\n",
    "        self.df['F136'] = self.rf_pred3\n",
    "        \n",
    "    def lvl4_Cargar_Caract(self):\n",
    "        #Se seleccionan las caracterisitcas del modelo\n",
    "        self.data4 = self.df[['Label', 'F3', 'F5', 'F9', 'F10', 'F11', 'F12', 'F13', \n",
    "                              'F15', 'F28', 'F29', 'F30', 'F31', 'F37', 'F42', 'F60', \n",
    "                              'F64', 'F69', 'F80', 'F81', 'F82', 'F89', 'F90', 'F91',\n",
    "                              'F94', 'F104', 'F105', 'F107', 'F112', 'F114', 'F115',\n",
    "                              'F129', 'F130', 'F135', 'F136']]\n",
    "        \n",
    "    def carga_Features4(self):\n",
    "        # Guardamos solo las caracteristicas para que los modelos del nivel 4 \n",
    "        # puedan hacer la prediccion\n",
    "        self.Xy4 = self.df[['F3', 'F5', 'F9', 'F10', 'F11', 'F12', 'F13', \n",
    "                            'F15', 'F28', 'F29', 'F30', 'F31', 'F37', 'F42', 'F60', \n",
    "                            'F64', 'F69', 'F80', 'F81', 'F82', 'F89', 'F90', 'F91',\n",
    "                            'F94', 'F104', 'F105', 'F107', 'F112', 'F114', 'F115',\n",
    "                            'F129', 'F130', 'F135', 'F136']]\n",
    "        \n",
    "    def lvl4_div_Datos(self):\n",
    "        # Dividimos los datos en entrenamiento y prueba\n",
    "        # X son nuestras variables independientes\n",
    "        self.X4 = self.data4.drop([\"Label\"],axis = 1)\n",
    "        \n",
    "        # y es nuestra variable dependiente\n",
    "        self.y4 = self.data4.Label\n",
    "        \n",
    "        # División 75% de datos para entrenamiento, 25% de datos para test\n",
    "        self.X_train4, self.X_test4, self.y_train4, self.y_test4 = train_test_split(self.X4, self.y4,random_state=0)\n",
    "        \n",
    "    def lvl4_creacion_DT(self):\n",
    "        # Creamos el modelo de Arbol de Decisión (y configuramos el número máximo de nodos-hoja)\n",
    "        self.Dt_model4 = tree.DecisionTreeClassifier(random_state = 0)\n",
    "    \n",
    "    def lvl4_entren_DT(self):\n",
    "        # Se entrena el arbol de decision del nivel 4\n",
    "        self.Dt_model4.fit(self.X_train4, self.y_train4)\n",
    "        \n",
    "    def lvl4_creacion_RF(self):\n",
    "        # Creamos el modelo Random Forest (se configura el numero de aboles, \n",
    "        # numero minimo de hojas y profundidad maxima)\n",
    "        self.BA_model4 = RandomForestClassifier(n_estimators = 20, random_state = 2016,)\n",
    "    \n",
    "    def lvl4_entren_RF(self):\n",
    "        # Se entrena el arbol de decision del nivel 4\n",
    "        self.BA_model4.fit(self.X_train4, self.y_train4)\n",
    "        \n",
    "    def lvl4_datos_Entren_DT(self):\n",
    "        # Muestra el accuracy de los datos de entrenamiento del DT4\n",
    "        print(\"Accuracy de entrenamiento Decision: \", self.Dt_model4.score(self.X_train4, self.y_train4))\n",
    "        self.dt_pred4 = self.Dt_model4.predict(self.X_train4)\n",
    "        # Muestra el F1 score de los datos de entrenamiento del DT4\n",
    "        print('F1 score:', f1_score(self.y_train4, self.dt_pred4))\n",
    "        # Muestra la matriz de confusion de los datos de entrenamiento del DT4\n",
    "        self.matriz = confusion_matrix(self.y_train4, self.dt_pred4)\n",
    "        plot_confusion_matrix(conf_mat=self.matriz, figsize=(4,4), show_normed=False)\n",
    "        plt.tight_layout()\n",
    "        plt.title('Matriz de Entrenamiento DT')\n",
    "        \n",
    "    def lvl4_datos_Entren_RF(self):\n",
    "        # Muestra el accuracy de los datos de entrenamiento del RF4\n",
    "        print(\"Accuracy de entrenamiento Random Forest: \", self.BA_model4.score(self.X_train4, self.y_train4))\n",
    "        self.rf_pred4 = self.BA_model4.predict(self.X_train4)\n",
    "        # Muestra el F1 score de los datos de entrenamiento del RF4\n",
    "        print('F1 score:', f1_score(self.y_train4, self.rf_pred4))\n",
    "        # Muestra la matriz de confusion de los datos de entrenamiento del RF4\n",
    "        self.matriz = confusion_matrix(self.y_train4, self.rf_pred4)\n",
    "        plot_confusion_matrix(conf_mat=self.matriz, figsize=(4,4), show_normed=False)\n",
    "        plt.tight_layout()\n",
    "        plt.title('Matriz de Entrenamiento RF')\n",
    "        \n",
    "    def lvl4_datos_Prueba_DT(self):\n",
    "        # Muestra el accuracy de los datos de prueba del DT4\n",
    "        print(\"Accuracy de prueba Decision Tree: \", self.Dt_model4.score(self.X_test4, self.y_test4))\n",
    "        self.dt_pred4 = self.Dt_model4.predict(self.X_test4)\n",
    "        # Muestra el F1 score de los datos de prueba del DT4\n",
    "        print('F1 score:', f1_score(self.y_test4, self.dt_pred4))\n",
    "        # Muestra la matriz de confusion de los datos de prueba del DT4\n",
    "        self.matriz = confusion_matrix(self.y_test4, self.dt_pred4)\n",
    "        plot_confusion_matrix(conf_mat=self.matriz, figsize=(4,4), show_normed=False)\n",
    "        plt.tight_layout()\n",
    "        plt.title('Matriz de Prueba DT')\n",
    "        \n",
    "    def lvl4_datos_Prueba_RF(self):\n",
    "        # Muestra el accuracy de los datos de prueba del RF4\n",
    "        print(\"Accuracy de prueba Random Forest: \", self.BA_model4.score(self.X_test4, self.y_test4))\n",
    "        self.rf_pred4 = self.BA_model4.predict(self.X_test4)\n",
    "        # Muestra el F1 score de los datos de prueba del RF4\n",
    "        print('F1 score:', f1_score(self.y_test4, self.rf_pred4))\n",
    "        # Muestra la matriz de confusion de los datos de prueba del RF4\n",
    "        self.matriz = confusion_matrix(self.y_test4, self.rf_pred4)\n",
    "        plot_confusion_matrix(conf_mat=self.matriz, figsize=(4,4), show_normed=False)\n",
    "        plt.tight_layout()\n",
    "        plt.title('Matriz de Prueba RF')\n",
    "        \n",
    "    def FP(self):\n",
    "        #Predict Finales\n",
    "        print('Prediccion final del Decision Tree:', self.Dt_model4.predict(self.Xy4))\n",
    "        print('Prediccion final del Random Forest', self.BA_model4.predict(self.Xy4))\n",
    "        \n",
    "    def k_FoldDt1(self):\n",
    "        # Dividimos los datos en entrenamiento y prueba\n",
    "        # X son nuestras variables independientes\n",
    "        # self.X1 = self.data.drop([\"Label\"],axis = 1)\n",
    "        \n",
    "        # y es nuestra variable dependiente\n",
    "        # self.y1 = self.data.Label\n",
    "        \n",
    "        K = 5  # Puedes ajustar K según tus necesidades\n",
    "        kf = KFold(n_splits=K, shuffle=True, random_state=0)\n",
    "        \n",
    "        scores1 = []\n",
    "        \n",
    "        for train_index, test_index in kf.split(self.X1):\n",
    "            self.X_train1, self.X_test1 = self.X1.iloc[train_index], self.X1.iloc[test_index]\n",
    "            self.y_train1, self.y_test1 = self.y1.iloc[train_index], self.y1.iloc[test_index]\n",
    "        \n",
    "            # Crea y entrena un modelo de árbol de decisión\n",
    "            self.model1 = tree.DecisionTreeClassifier(random_state=0)\n",
    "            self.model1.fit(self.X_train1, self.y_train1)\n",
    "        \n",
    "            # Realiza predicciones en el conjunto de prueba\n",
    "            self.y_pred1 = self.model1.predict(self.X_test1)\n",
    "        \n",
    "            # Evalúa el rendimiento del modelo (puedes usar métricas como precisión, F1-score, etc.)\n",
    "            accuracy1 = accuracy_score(self.y_test1, self.y_pred1)\n",
    "            scores1.append(accuracy1)\n",
    "            print('Precición de K-Fold por iteración', accuracy1)\n",
    "            \n",
    "        # Calcula el promedio de las puntuaciones de precisión de los pliegues\n",
    "        average_accuracy1 = np.mean(scores1)\n",
    "        print(f'Precisión promedio en {K}-Fold Cross-Validation: {average_accuracy1}')\n",
    "            \n",
    "    def k_FoldRf1(self):\n",
    "        # Dividimos los datos en entrenamiento y prueba\n",
    "        # X son nuestras variables independientes\n",
    "        # self.X1 = self.data.drop([\"Label\"],axis = 1)\n",
    "        \n",
    "        # y es nuestra variable dependiente\n",
    "        # self.y1 = self.data.Label\n",
    "        \n",
    "        K = 5  # Puedes ajustar K según tus necesidades\n",
    "        kf = KFold(n_splits=K, shuffle=True, random_state=0)\n",
    "        \n",
    "        scores2 = []\n",
    "        \n",
    "        for train_index, test_index in kf.split(self.X1):\n",
    "            self.X_train1, self.X_test1 = self.X1.iloc[train_index], self.X1.iloc[test_index]\n",
    "            self.y_train1, self.y_test1 = self.y1.iloc[train_index], self.y1.iloc[test_index]\n",
    "        \n",
    "            # Crea y entrena un modelo de árbol de decisión\n",
    "            self.model2 = tree.DecisionTreeClassifier(random_state=0)\n",
    "            self.model2.fit(self.X_train1, self.y_train1)\n",
    "        \n",
    "            # Realiza predicciones en el conjunto de prueba\n",
    "            self.y_pred2 = self.model2.predict(self.X_test1)\n",
    "        \n",
    "            # Evalúa el rendimiento del modelo (puedes usar métricas como precisión, F1-score, etc.)\n",
    "            accuracy2 = accuracy_score(self.y_test1, self.y_pred2)\n",
    "            scores2.append(accuracy2)\n",
    "            print('Precición de K-Fold por iteración', accuracy2)\n",
    "        \n",
    "        # Calcula el promedio de las puntuaciones de precisión de los pliegues\n",
    "        average_accuracy2 = np.mean(scores2)\n",
    "        print(f'Precisión promedio en {K}-Fold Cross-Validation: {average_accuracy2}')\n",
    "        \n",
    "    def k_FoldDt2(self):\n",
    "        # Dividimos los datos en entrenamiento y prueba\n",
    "        # X son nuestras variables independientes\n",
    "        # self.X2 = self.data.drop([\"Label\"],axis = 1)\n",
    "        \n",
    "        # y es nuestra variable dependiente\n",
    "        # self.y2 = self.data.Label\n",
    "        \n",
    "        K = 5  # Puedes ajustar K según tus necesidades\n",
    "        kf = KFold(n_splits=K, shuffle=True, random_state=0)\n",
    "        \n",
    "        scores3 = []\n",
    "        \n",
    "        for train_index, test_index in kf.split(self.X2):\n",
    "            self.X_train2, self.X_test2 = self.X2.iloc[train_index], self.X2.iloc[test_index]\n",
    "            self.y_train2, self.y_test2 = self.y2.iloc[train_index], self.y2.iloc[test_index]\n",
    "        \n",
    "            # Crea y entrena un modelo de árbol de decisión\n",
    "            self.model3 = tree.DecisionTreeClassifier(random_state=0)\n",
    "            self.model3.fit(self.X_train2, self.y_train2)\n",
    "        \n",
    "            # Realiza predicciones en el conjunto de prueba\n",
    "            self.y_pred3 = self.model3.predict(self.X_test2)\n",
    "        \n",
    "            # Evalúa el rendimiento del modelo (puedes usar métricas como precisión, F1-score, etc.)\n",
    "            accuracy3 = accuracy_score(self.y_test2, self.y_pred3)\n",
    "            scores3.append(accuracy3)\n",
    "            print('Precición de K-Fold por iteración', accuracy3)\n",
    "            \n",
    "        # Calcula el promedio de las puntuaciones de precisión de los pliegues\n",
    "        average_accuracy3 = np.mean(scores3)\n",
    "        print(f'Precisión promedio en {K}-Fold Cross-Validation: {average_accuracy3}')\n",
    "            \n",
    "    def k_FoldRf2(self):\n",
    "        # Dividimos los datos en entrenamiento y prueba\n",
    "        # X son nuestras variables independientes\n",
    "        # self.X2 = self.data.drop([\"Label\"],axis = 1)\n",
    "        \n",
    "        # y es nuestra variable dependiente\n",
    "        # self.y2 = self.data.Label\n",
    "        \n",
    "        K = 5  # Puedes ajustar K según tus necesidades\n",
    "        kf = KFold(n_splits=K, shuffle=True, random_state=0)\n",
    "        \n",
    "        scores4 = []\n",
    "        \n",
    "        for train_index, test_index in kf.split(self.X2):\n",
    "            self.X_train2, self.X_test2 = self.X2.iloc[train_index], self.X2.iloc[test_index]\n",
    "            self.y_train2, self.y_test2 = self.y2.iloc[train_index], self.y2.iloc[test_index]\n",
    "        \n",
    "            # Crea y entrena un modelo de árbol de decisión\n",
    "            self.model4 = tree.DecisionTreeClassifier(random_state=0)\n",
    "            self.model4.fit(self.X_train2, self.y_train2)\n",
    "        \n",
    "            # Realiza predicciones en el conjunto de prueba\n",
    "            self.y_pred4 = self.model4.predict(self.X_test2)\n",
    "        \n",
    "            # Evalúa el rendimiento del modelo (puedes usar métricas como precisión, F1-score, etc.)\n",
    "            accuracy4 = accuracy_score(self.y_test2, self.y_pred4)\n",
    "            scores4.append(accuracy4)\n",
    "            print('Precición de K-Fold por iteración', accuracy4)\n",
    "        \n",
    "        # Calcula el promedio de las puntuaciones de precisión de los pliegues\n",
    "        average_accuracy4 = np.mean(scores4)\n",
    "        print(f'Precisión promedio en {K}-Fold Cross-Validation: {average_accuracy4}')\n",
    "        \n",
    "    def k_FoldDt3(self):\n",
    "        # Dividimos los datos en entrenamiento y prueba\n",
    "        # X son nuestras variables independientes\n",
    "        # self.X3 = self.data.drop([\"Label\"],axis = 1)\n",
    "        \n",
    "        # y es nuestra variable dependiente\n",
    "        # self.y3 = self.data.Label\n",
    "        \n",
    "        K = 5  # Puedes ajustar K según tus necesidades\n",
    "        kf = KFold(n_splits=K, shuffle=True, random_state=0)\n",
    "        \n",
    "        scores5 = []\n",
    "        \n",
    "        for train_index, test_index in kf.split(self.X3):\n",
    "            self.X_train3, self.X_test3 = self.X3.iloc[train_index], self.X3.iloc[test_index]\n",
    "            self.y_train3, self.y_test3 = self.y3.iloc[train_index], self.y3.iloc[test_index]\n",
    "        \n",
    "            # Crea y entrena un modelo de árbol de decisión\n",
    "            self.model5 = tree.DecisionTreeClassifier(random_state=0)\n",
    "            self.model5.fit(self.X_train3, self.y_train3)\n",
    "        \n",
    "            # Realiza predicciones en el conjunto de prueba\n",
    "            self.y_pred5 = self.model5.predict(self.X_test3)\n",
    "        \n",
    "            # Evalúa el rendimiento del modelo (puedes usar métricas como precisión, F1-score, etc.)\n",
    "            accuracy5 = accuracy_score(self.y_test3, self.y_pred5)\n",
    "            scores5.append(accuracy5)\n",
    "            print('Precición de K-Fold por iteración', accuracy5)\n",
    "            \n",
    "        # Calcula el promedio de las puntuaciones de precisión de los pliegues\n",
    "        average_accuracy5 = np.mean(scores5)\n",
    "        print(f'Precisión promedio en {K}-Fold Cross-Validation: {average_accuracy5}')\n",
    "            \n",
    "    def k_FoldRf3(self):\n",
    "        # Dividimos los datos en entrenamiento y prueba\n",
    "        # X son nuestras variables independientes\n",
    "        # self.X3 = self.data.drop([\"Label\"],axis = 1)\n",
    "        \n",
    "        # y es nuestra variable dependiente\n",
    "        # self.y3 = self.data.Label\n",
    "        \n",
    "        K = 5  # Puedes ajustar K según tus necesidades\n",
    "        kf = KFold(n_splits=K, shuffle=True, random_state=0)\n",
    "        \n",
    "        scores6 = []\n",
    "        \n",
    "        for train_index, test_index in kf.split(self.X3):\n",
    "            self.X_train3, self.X_test3 = self.X3.iloc[train_index], self.X3.iloc[test_index]\n",
    "            self.y_train3, self.y_test3 = self.y3.iloc[train_index], self.y3.iloc[test_index]\n",
    "        \n",
    "            # Crea y entrena un modelo de árbol de decisión\n",
    "            self.model6 = tree.DecisionTreeClassifier(random_state=0)\n",
    "            self.model6.fit(self.X_train3, self.y_train3)\n",
    "        \n",
    "            # Realiza predicciones en el conjunto de prueba\n",
    "            self.y_pred6 = self.model6.predict(self.X_test3)\n",
    "        \n",
    "            # Evalúa el rendimiento del modelo (puedes usar métricas como precisión, F1-score, etc.)\n",
    "            accuracy6 = accuracy_score(self.y_test3, self.y_pred6)\n",
    "            scores6.append(accuracy6)\n",
    "            print('Precición de K-Fold por iteración', accuracy6)\n",
    "        \n",
    "        # Calcula el promedio de las puntuaciones de precisión de los pliegues\n",
    "        average_accuracy6 = np.mean(scores6)\n",
    "        print(f'Precisión promedio en {K}-Fold Cross-Validation: {average_accuracy6}')\n",
    "        \n",
    "    def k_FoldDt4(self):\n",
    "        # Dividimos los datos en entrenamiento y prueba\n",
    "        # X son nuestras variables independientes\n",
    "        # self.X4 = self.data.drop([\"Label\"],axis = 1)\n",
    "        \n",
    "        # y es nuestra variable dependiente\n",
    "        # self.y4 = self.data.Label\n",
    "        \n",
    "        K = 5  # Puedes ajustar K según tus necesidades\n",
    "        kf = KFold(n_splits=K, shuffle=True, random_state=0)\n",
    "        \n",
    "        scores7 = []\n",
    "        \n",
    "        for train_index, test_index in kf.split(self.X4):\n",
    "            self.X_train4, self.X_test4 = self.X4.iloc[train_index], self.X4.iloc[test_index]\n",
    "            self.y_train4, self.y_test4 = self.y4.iloc[train_index], self.y4.iloc[test_index]\n",
    "        \n",
    "            # Crea y entrena un modelo de árbol de decisión\n",
    "            self.model7 = tree.DecisionTreeClassifier(random_state=0)\n",
    "            self.model7.fit(self.X_train4, self.y_train4)\n",
    "        \n",
    "            # Realiza predicciones en el conjunto de prueba\n",
    "            self.y_pred7 = self.model7.predict(self.X_test4)\n",
    "        \n",
    "            # Evalúa el rendimiento del modelo (puedes usar métricas como precisión, F1-score, etc.)\n",
    "            accuracy7 = accuracy_score(self.y_test4, self.y_pred7)\n",
    "            scores7.append(accuracy7)\n",
    "            print('Precición de K-Fold por iteración', accuracy7)\n",
    "            \n",
    "        # Calcula el promedio de las puntuaciones de precisión de los pliegues\n",
    "        average_accuracy7 = np.mean(scores7)\n",
    "        print(f'Precisión promedio en {K}-Fold Cross-Validation: {average_accuracy7}')\n",
    "            \n",
    "    def k_FoldRf4(self):\n",
    "        # Dividimos los datos en entrenamiento y prueba\n",
    "        # X son nuestras variables independientes\n",
    "        # self.X4 = self.data.drop([\"Label\"],axis = 1)\n",
    "        \n",
    "        # y es nuestra variable dependiente\n",
    "        # self.y4 = self.data.Label\n",
    "        \n",
    "        K = 5  # Puedes ajustar K según tus necesidades\n",
    "        kf = KFold(n_splits=K, shuffle=True, random_state=0)\n",
    "        \n",
    "        scores8 = []\n",
    "        \n",
    "        for train_index, test_index in kf.split(self.X4):\n",
    "            self.X_train4, self.X_test4 = self.X4.iloc[train_index], self.X4.iloc[test_index]\n",
    "            self.y_train4, self.y_test4 = self.y4.iloc[train_index], self.y4.iloc[test_index]\n",
    "        \n",
    "            # Crea y entrena un modelo de árbol de decisión\n",
    "            self.model8 = tree.DecisionTreeClassifier(random_state=0)\n",
    "            self.model8.fit(self.X_train4, self.y_train4)\n",
    "        \n",
    "            # Realiza predicciones en el conjunto de prueba\n",
    "            self.y_pred8 = self.model8.predict(self.X_test4)\n",
    "        \n",
    "            # Evalúa el rendimiento del modelo (puedes usar métricas como precisión, F1-score, etc.)\n",
    "            accuracy8 = accuracy_score(self.y_test4, self.y_pred8)\n",
    "            scores8.append(accuracy8)\n",
    "            print('Precición de K-Fold por iteración', accuracy8)\n",
    "        \n",
    "        # Calcula el promedio de las puntuaciones de precisión de los pliegues\n",
    "        average_accuracy8 = np.mean(scores8)\n",
    "        print(f'Precisión promedio en {K}-Fold Cross-Validation: {average_accuracy8}')\n",
    "        \n",
    "    def expDashDt1(self):\n",
    "        # Convierte las features a int y luego a float\n",
    "        self.X1 = self.X1.astype(int)\n",
    "        self.X1 = self.X1.astype(float)\n",
    "        # Llama al explainer dashboard para DT nivel 1\n",
    "        explainer = ClassifierExplainer(self.Dt_model1, self.X1, self.y1)\n",
    "        ExplainerDashboard(explainer).run(port=8051)\n",
    "        \n",
    "    def expDashRf1(self):\n",
    "        # Convierte las features a int y luego a float\n",
    "        self.X1 = self.X1.astype(int)\n",
    "        self.X1 = self.X1.astype(float)\n",
    "        # Llama al explainer dashboard para RF nivel 3\n",
    "        explainer = ClassifierExplainer(self.BA_model1, self.X1, self.y1)\n",
    "        ExplainerDashboard(explainer).run(port=8051)\n",
    "        \n",
    "    def expDashDt2(self):\n",
    "        # Convierte las features a int y luego a float\n",
    "        self.X2 = self.X2.astype(int)\n",
    "        self.X2 = self.X2.astype(float)\n",
    "        # Llama al explainer dashboard para DT nivel 1\n",
    "        explainer = ClassifierExplainer(self.Dt_model2, self.X2, self.y2)\n",
    "        ExplainerDashboard(explainer).run(port=8051)\n",
    "        \n",
    "    def expDashRf2(self):\n",
    "        # Convierte las features a int y luego a float\n",
    "        self.X2 = self.X2.astype(int)\n",
    "        self.X2 = self.X2.astype(float)\n",
    "        # Llama al explainer dashboard para RF nivel 1\n",
    "        explainer = ClassifierExplainer(self.BA_model2, self.X2, self.y2)\n",
    "        ExplainerDashboard(explainer).run(port=8051)\n",
    "        \n",
    "    def expDashDt3(self):\n",
    "        # Convierte las features a int y luego a float\n",
    "        self.X3 = self.X3.astype(int)\n",
    "        self.X3 = self.X3.astype(float)\n",
    "        # Llama al explainer dashboard para DT nivel 3\n",
    "        explainer = ClassifierExplainer(self.Dt_model3, self.X3, self.y3)\n",
    "        ExplainerDashboard(explainer).run(port=8051)\n",
    "        \n",
    "    def expDashRf3(self):\n",
    "        # Convierte las features a int y luego a float\n",
    "        self.X3 = self.X3.astype(int)\n",
    "        self.X3 = self.X3.astype(float)\n",
    "        # Llama al explainer dashboard para RF nivel 3\n",
    "        explainer = ClassifierExplainer(self.BA_model3, self.X3, self.y3)\n",
    "        ExplainerDashboard(explainer).run(port=8051)\n",
    "        \n",
    "    def expDashDt4(self):\n",
    "        # Convierte las features a int y luego a float\n",
    "        self.X4 = self.X4.astype(int)\n",
    "        self.X4 = self.X4.astype(float)\n",
    "        # Llama al explainer dashboard para DT nivel 4\n",
    "        explainer = ClassifierExplainer(self.Dt_model4, self.X4, self.y4)\n",
    "        ExplainerDashboard(explainer).run(port=8051)\n",
    "        \n",
    "    def expDashRf4(self):\n",
    "        # Convierte las features a int y luego a float\n",
    "        self.X4 = self.X4.astype(int)\n",
    "        self.X4 = self.X4.astype(float)\n",
    "        # Llama al explainer dashboard para RF nivel 4\n",
    "        explainer = ClassifierExplainer(self.BA_model4, self.X4, self.y4)\n",
    "        ExplainerDashboard(explainer).run(port=8051)\n",
    "    \n",
    "    def guardar_Modelo1(self, nomMod1):\n",
    "        # Guarda los modelos entrenados del nivel 1\n",
    "        # Es necesario ingresar el nombre del modelo y añadir \".plk\" al final\n",
    "        # El codigo añadira el prefijo del tipo del modelo y nivel del modelo\n",
    "        # Ejemplo: DT1 Decision Tree de nivel 1 y RF1 Random Forest de nivel 1\n",
    "        joblib.dump(self.Dt_model1, 'DT1'+nomMod1)\n",
    "        joblib.dump(self.BA_model1, 'RF1'+nomMod1)\n",
    "        \n",
    "    def guardar_Modelo2(self, nomMod1):\n",
    "        # Guarda los modelos entrenados del nivel 2\n",
    "        # Es necesario ingresar el nombre del modelo y añadir \".plk\" al final\n",
    "        # El codigo añadira el prefijo del tipo del modelo y nivel del modelo\n",
    "        # Ejemplo: DT1 Decision Tree de nivel 1 y RF1 Random Forest de nivel 1\n",
    "        joblib.dump(self.Dt_model2, 'DT2'+nomMod1)\n",
    "        joblib.dump(self.BA_model2, 'RF2'+nomMod1)\n",
    "        \n",
    "    def guardar_Modelo3(self, nomMod1):\n",
    "        # Guarda los modelos entrenados del nivel 3\n",
    "        # Es necesario ingresar el nombre del modelo y añadir \".plk\" al final\n",
    "        # El codigo añadira el prefijo del tipo del modelo y nivel del modelo\n",
    "        # Ejemplo: DT1 Decision Tree de nivel 1 y RF1 Random Forest de nivel 1\n",
    "        joblib.dump(self.Dt_model3, 'DT3'+nomMod1)\n",
    "        joblib.dump(self.BA_model3, 'RF3'+nomMod1)\n",
    "        \n",
    "    def guardar_Modelo4(self, nomMod1):\n",
    "        # Guarda los modelos entrenados del nivel 4\n",
    "        # Es necesario ingresar el nombre del modelo y añadir \".plk\" al final\n",
    "        # El codigo añadira el prefijo del tipo del modelo y nivel del modelo\n",
    "        # Ejemplo: DT1 Decision Tree de nivel 1 y RF1 Random Forest de nivel 1\n",
    "        joblib.dump(self.Dt_model4, 'DT4'+nomMod1)\n",
    "        joblib.dump(self.BA_model4, 'RF4'+nomMod1)\n",
    "        \n",
    "    def carga_Modelo(self, modelo):\n",
    "        # El modelo se carga\n",
    "        # El modelo debe de ser un .pkl\n",
    "        # No es necesario escribir el prefijo de cada modelo, el programa lo \n",
    "        # hara automaticamente, solo hay que verificar que todos los modelos\n",
    "        # tengan el mismo nombre excluyendo el prefijo DT# y RF# \n",
    "        self.Dt_model1 = joblib.load('DT1'+modelo)\n",
    "        self.BA_model1 = joblib.load('DT1'+modelo)\n",
    "        self.Dt_model2 = joblib.load('DT2'+modelo)\n",
    "        self.BA_model2 = joblib.load('RF2'+modelo)\n",
    "        self.Dt_model3 = joblib.load('DT3'+modelo)\n",
    "        self.BA_model3 = joblib.load('RF3'+modelo)\n",
    "        self.Dt_model4 = joblib.load('DT4'+modelo)\n",
    "        self.BA_model4 = joblib.load('RF4'+modelo)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d451fd",
   "metadata": {},
   "source": [
    "# Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b88d7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento para nivel 1\n",
    "df = SQLIAD()\n",
    "df.carga_Dataset('Nombre_dataset.csv')\n",
    "df.iden_Caract()\n",
    "df.lvl1_Cargar_Caract()\n",
    "df.lvl1_div_Datos()\n",
    "df.lvl1_creacion_DT()\n",
    "df.lvl1_creacion_RF()\n",
    "df.lvl1_entren_DT()\n",
    "df.lvl1_entren_RF()\n",
    "df.generacion_NC1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991dd232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrices de confusión nivel 1\n",
    "# df.lvl1_datos_Entren_DT()\n",
    "# df.lvl1_datos_Entren_RF()\n",
    "# df.lvl1_datos_Prueba_DT()\n",
    "# df.lvl1_datos_Prueba_RF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0572ed3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento para nivel 2\n",
    "df.lvl2_Cargar_Caract()\n",
    "df.lvl2_div_Datos()\n",
    "df.lvl2_creacion_DT()\n",
    "df.lvl2_creacion_RF()\n",
    "df.lvl2_entren_DT()\n",
    "df.lvl2_entren_RF()\n",
    "df.generacion_NC2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925a86fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrices de confusión nivel 2\n",
    "# df.lvl2_datos_Entren_DT()\n",
    "# df.lvl2_datos_Entren_RF()\n",
    "# df.lvl2_datos_Prueba_DT()\n",
    "# df.lvl2_datos_Prueba_RF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b3734f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento para nivel 3\n",
    "df.lvl3_Cargar_Caract()\n",
    "df.lvl3_div_Datos()\n",
    "df.lvl3_creacion_DT()\n",
    "df.lvl3_creacion_RF()\n",
    "df.lvl3_entren_DT()\n",
    "df.lvl3_entren_RF()\n",
    "df.generacion_NC3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fbdad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrices de confusión nivel 3\n",
    "# df.lvl3_datos_Entren_DT()\n",
    "# df.lvl3_datos_Entren_RF()\n",
    "# df.lvl3_datos_Prueba_DT()\n",
    "# df.lvl3_datos_Prueba_RF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b438a9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.lvl4_Cargar_Caract()\n",
    "df.lvl4_div_Datos()\n",
    "df.lvl4_creacion_DT()\n",
    "df.lvl4_creacion_RF()\n",
    "df.lvl4_entren_DT()\n",
    "df.lvl4_entren_RF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5675f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrices de confusión nivel 4\n",
    "# df.lvl4_datos_Entren_DT()\n",
    "# df.lvl4_datos_Entren_RF()\n",
    "# df.lvl4_datos_Prueba_DT()\n",
    "# df.lvl4_datos_Prueba_RF()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e29892",
   "metadata": {},
   "source": [
    "# Comprobación con cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09f3497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Como se necesita una caracteristica generada de los modelos anteriores es necesario \n",
    "# entrenar hasta el nivel anterior para poder usar los Nivel 2, 3 y 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddc0127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nivel 1\n",
    "df.k_FoldDt1()\n",
    "print('-------------------------------------------------------------------')\n",
    "df.k_FoldRf1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a53f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nivel 2\n",
    "df.k_FoldDt2()\n",
    "print('-------------------------------------------------------------------')\n",
    "df.k_FoldRf2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c784dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nivel 3\n",
    "df.k_FoldDt3()\n",
    "print('-------------------------------------------------------------------')\n",
    "df.k_FoldRf3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158222ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nivel 4\n",
    "df.k_FoldDt4()\n",
    "print('-------------------------------------------------------------------')\n",
    "df.k_FoldRf4()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa2ae80",
   "metadata": {},
   "source": [
    "# Predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31311107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dt = SQLIAD()\n",
    "df.carga_Dato('Dato a predecir')\n",
    "df.iden_Caract()\n",
    "df.carga_Features1()\n",
    "# Los modelos se guardaran automaticamente con un prefijo (DT# o RF#), no necesita escribir \n",
    "# el prefijo ya que se cargaran todos los modelos siempre y cuando tengan el mismo nombre base\n",
    "# Ejemplo: df.carga_Modelo('Modelo.pkl') en caso de que se llamen DT1Modelo.pkl, RF1Modelo.pkl, DT2Modelo.pkl, etc\n",
    "# df.carga_Modelo('Nombre_modelo.pkl') # Esta linea solo es necesaria si quiere cargar los modelos\n",
    "df.gNC1()\n",
    "df.carga_Features2()\n",
    "df.gNC2()\n",
    "df.carga_Features3()\n",
    "df.gNC3()\n",
    "df.carga_Features4()\n",
    "df.FP()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2e5634",
   "metadata": {},
   "source": [
    "# Guardar modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d336c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Los modelos se guardan con un prefijo automaticamente por nivel (DT# y RF#) donde # es el número del nivel\n",
    "df.guardar_Modelo1('Nombre_modelo.pkl') # Nivel 1\n",
    "df.guardar_Modelo2('Nombre_modelo.pkl') # Nivel 2\n",
    "df.guardar_Modelo3('Nombre_modelo.pkl') # Nivel 3\n",
    "df.guardar_Modelo4('Nombre_modelo.pkl') # Nivel 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf121f3",
   "metadata": {},
   "source": [
    "# Cargar modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cd650e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Los modelos se guardaran automaticamente con un prefijo (DT# o RF#), no necesita escribir \n",
    "# el prefijo ya que se cargaran todos los modelos siempre y cuando tengan el mismo nombre base\n",
    "# Ejemplo: df.carga_Modelo('Modelo.pkl') en caso de que se llamen DT1Modelo.pkl, RF1Modelo.pkl, DT2Modelo.pkl, etc\n",
    "df.carga_Modelo('Nombre_modelo.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1c668b",
   "metadata": {},
   "source": [
    "# Explainerdashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b35346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# El explainerdashboard se puede ejecutar por modelo, solo se puede correr 1 a la vez\n",
    "df.expDashDt1()\n",
    "# df.expDashRf1()\n",
    "# df.expDashDt2()\n",
    "# df.expDashRf2()\n",
    "# df.expDashDt3()\n",
    "# df.expDashRf3()\n",
    "# df.expDashDt4()\n",
    "# df.expDashRf4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54abdee3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
